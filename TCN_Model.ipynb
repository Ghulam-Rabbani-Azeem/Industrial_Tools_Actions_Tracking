{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb39ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# 1. Import necessary packages (no changes needed here)\n",
    "# %%\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# %% [markdown]\n",
    "# 2. Set random seed for reproducibility (no changes needed)\n",
    "# %%\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# %% [markdown]\n",
    "# 3. Load the train data (no changes needed)\n",
    "# %%\n",
    "mytool = \"electric_screwdriver\" # pneumatic_screwdriver,electric_screwdriver\n",
    "output_dir = \"./processed_data/\"\n",
    "combined_data = np.load(os.path.join(output_dir, f\"combined_data_train_{mytool}.npy\"))\n",
    "combined_labels = np.load(os.path.join(output_dir, f\"combined_label_train_{mytool}.npy\"))\n",
    "\n",
    "# %% [markdown]\n",
    "# 4. Perform training with k fold validation\n",
    "# %%\n",
    "if mytool == \"electric_screwdriver\":\n",
    "    label_info = {\n",
    "        2: 'tightening',\n",
    "        3: 'untightening',\n",
    "        4: 'motor_activity_cw',\n",
    "        5: 'motor_activity_ccw',\n",
    "        6: 'manual_motor_rotation',\n",
    "        7: 'shaking',\n",
    "        14: 'tightening_double'\n",
    "    }\n",
    "elif mytool == \"pneumatic_screwdriver\":\n",
    "    label_info = {\n",
    "        2: 'tightening',\n",
    "        3: 'untightening',\n",
    "        4: 'motor_activity_cw',\n",
    "        5: 'motor_activity_ccw',\n",
    "        7: 'shaking',\n",
    "        14: 'tightening_double',\n",
    "        38: 'impact'\n",
    "    }\n",
    "\n",
    "valid_labels = list(label_info.keys())\n",
    "\n",
    "# Training data and labels\n",
    "X = combined_data\n",
    "y = combined_labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "X_tensor = torch.FloatTensor(X)\n",
    "y_tensor = torch.LongTensor(y_encoded)\n",
    "\n",
    "# ---------------- TCN Model Implementation ---------------- #\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size=3, dropout=0.2):\n",
    "        super(TCN, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        \n",
    "        for i in range(num_levels):\n",
    "            dilation = 2 ** i\n",
    "            in_channels = input_size if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, \n",
    "                                   stride=1, dilation=dilation,\n",
    "                                   padding=(kernel_size-1) * dilation, \n",
    "                                   dropout=dropout)]\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, seq_len, input_size)\n",
    "        x = x.transpose(1, 2)  # Change to (batch_size, input_size, seq_len)\n",
    "        x = self.network(x)\n",
    "        x = self.linear(x[:, :, -1])  # Take last timestep\n",
    "        return x\n",
    "\n",
    "class SimpleFocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None):\n",
    "        super(SimpleFocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = torch.tensor(alpha, dtype=torch.float32) if alpha is not None else None\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        device = inputs.device\n",
    "        log_probs = F.log_softmax(inputs, dim=1)\n",
    "        probs = log_probs.exp()\n",
    "        log_probs_true = log_probs.gather(1, targets.view(-1, 1)).squeeze(1)\n",
    "        probs_true = probs.gather(1, targets.view(-1, 1)).squeeze(1).clamp(min=1e-9)\n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha.to(device)[targets]\n",
    "            loss = -alpha_t * (1 - probs_true)**self.gamma * log_probs_true\n",
    "        else:\n",
    "            loss = - (1 - probs_true)**self.gamma * log_probs_true\n",
    "        return loss.mean()\n",
    "\n",
    "# ---------------- K-Fold Training Loop ---------------- #\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_dim = X.shape[2]\n",
    "output_dim = len(label_info)\n",
    "num_channels = [64, 64, 64]  # Number of channels in each TCN layer\n",
    "batch_size = 32\n",
    "num_epochs = 200 if mytool == \"pneumatic_screwdriver\" else 100\n",
    "\n",
    "fold_accuracies, fold_f1s = [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_tensor, y_tensor)):\n",
    "    print(f\"\\n--- Fold {fold+1} ---\")\n",
    "\n",
    "    X_train, X_val = X_tensor[train_idx], X_tensor[val_idx]\n",
    "    y_train, y_val = y_tensor[train_idx], y_tensor[val_idx]\n",
    "\n",
    "    # Weighted Sampling for class imbalance\n",
    "    class_sample_counts = np.array([(y_train == t).sum() for t in torch.unique(y_train)])\n",
    "    weights = 1. / class_sample_counts\n",
    "    samples_weight = np.array([weights[t] for t in y_train.numpy()])\n",
    "    samples_weight = torch.from_numpy(samples_weight).float()\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    if mytool == \"pneumatic_screwdriver\":\n",
    "        train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, sampler=sampler)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = TCN(input_size=input_dim, output_size=output_dim, num_channels=num_channels).to(device)\n",
    "    criterion = SimpleFocalLoss(gamma=2.0)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "    train_losses, valid_losses = [], []\n",
    "    train_accuracies, valid_accuracies = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        train_accuracies.append(correct / total)\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                valid_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        valid_losses.append(valid_loss / len(val_loader))\n",
    "        valid_accuracies.append(correct / total)\n",
    "        print(f\"Epoch {epoch+1}: Train Acc = {train_accuracies[-1]:.4f}, Val Acc = {valid_accuracies[-1]:.4f}\")\n",
    "\n",
    "    # Final Evaluation on Validation Set\n",
    "    y_true, y_pred = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    fold_accuracies.append(acc)\n",
    "    fold_f1s.append(f1)\n",
    "\n",
    "    # Training Curves\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(valid_losses, label='Valid Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Train Acc')\n",
    "    plt.plot(valid_accuracies, label='Valid Acc')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    print(f\"\\nFold {fold+1} Accuracy: {acc:.4f}\")\n",
    "    print(f\"Fold {fold+1} Weighted F1 Score: {f1:.4f}\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[label_info[i] for i in valid_labels]))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_info.values(), yticklabels=label_info.values())\n",
    "    plt.title(f'Fold {fold+1} Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "    # Save model\n",
    "    model_dir = \"./trained_model/\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_file = os.path.join(model_dir, f\"tcn_model{fold}_{mytool}.pth\")\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print(f\"Model successfully saved to {model_file}.\")\n",
    "\n",
    "# ---------------- Overall Summary ---------------- #\n",
    "print(f\"\\nAverage Accuracy over {n_splits} folds: {np.mean(fold_accuracies):.4f}\")\n",
    "print(f\"Average Weighted F1 Score over {n_splits} folds: {np.mean(fold_f1s):.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# 6. Load the TCN model for testing\n",
    "# %%\n",
    "num_of_classes = len(label_info)\n",
    "split_count = 4\n",
    "loaded_model = TCN(input_size=X.shape[2], output_size=num_of_classes, num_channels=[64, 64, 64])\n",
    "loaded_model.to(device)\n",
    "\n",
    "model_file = os.path.join(model_dir, f\"tcn_model{split_count}_{mytool}.pth\")\n",
    "loaded_model.load_state_dict(torch.load(model_file, map_location=device))\n",
    "loaded_model.eval()\n",
    "print(\"Model successfully loaded.\")\n",
    "\n",
    "# %% [markdown]\n",
    "# 7. Evaluate the model on test data (no changes needed except model name)\n",
    "# %%\n",
    "output_dir = \"./processed_data/\"\n",
    "combined_data_test = np.load(os.path.join(output_dir, f\"combined_data_test_{mytool}.npy\"))\n",
    "combined_labels_test = np.load(os.path.join(output_dir, f\"combined_label_test_{mytool}.npy\"))\n",
    "\n",
    "X = combined_data_test\n",
    "y = combined_labels_test\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "X_tensor_test = torch.FloatTensor(X)\n",
    "y_tensor_test = torch.LongTensor(y_encoded)\n",
    "\n",
    "new_loader = DataLoader(TensorDataset(X_tensor_test, y_tensor_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Perform evaluation:\n",
    "loaded_model.eval()\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in new_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = loaded_model(inputs)\n",
    "        preds = outputs.argmax(1)\n",
    "        predicted_labels.extend(preds.cpu().numpy()) \n",
    "        true_labels.extend(labels.numpy()) \n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "print(f\"\\nFinal Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Final Weighted F1 Score: {f1:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "class_names = [label_info[i] for i in valid_labels]\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_names))\n",
    "\n",
    "results_file = \"results.csv\"\n",
    "tool_type = mytool\n",
    "header = ['tool_type', 'split_count', 'accuracy', 'f1']\n",
    "file_exists = os.path.exists(results_file)\n",
    "\n",
    "with open(results_file, mode='a', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    if not file_exists:\n",
    "        writer.writerow(header)\n",
    "    writer.writerow([tool_type, split_count, round(accuracy * 100, 2), round(f1 * 100, 2)])\n",
    "\n",
    "print(f\"Results successfully recorded in {results_file}.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
