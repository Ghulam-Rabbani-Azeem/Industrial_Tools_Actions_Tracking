{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70d2df81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Titles and Frequencies:\n",
      "8: 5391\n",
      "2: 821\n",
      "3: 334\n",
      "4: 298\n",
      "5: 131\n",
      "7: 87\n",
      "6: 67\n",
      "14: 12\n",
      "\n",
      "Additional Statistics:\n",
      "Total number of labels: 7141\n",
      "Number of unique labels: 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Load the combined_labels.npy file\n",
    "combined_labels = np.load('combined_labels.npy', allow_pickle=True)\n",
    "\n",
    "combined_data = np.load('combined_data.npy', allow_pickle=True)\n",
    "\n",
    "# If the labels are in a structured format (e.g., dictionary), you might need to adjust\n",
    "# For simplicity, assuming it's a 1D array of labels\n",
    "labels = combined_labels\n",
    "\n",
    "# Count the frequency of each label\n",
    "label_counts = Counter(labels)\n",
    "\n",
    "# Print the unique labels and their frequencies\n",
    "print(\"Label Titles and Frequencies:\")\n",
    "for label, count in label_counts.most_common():\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "# Additional statistics\n",
    "print(\"\\nAdditional Statistics:\")\n",
    "print(f\"Total number of labels: {len(labels)}\")\n",
    "print(f\"Number of unique labels: {len(label_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189459c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Combined data shape: (7141, 41, 22)\n",
      "[INFO] Combined label shape: (7141,)\n",
      "[INFO] Example entry (first window, first time step): [-5.87737800e+00  1.32205100e+00  8.61249100e+00 -1.06526400e-02\n",
      "  1.17179100e-02 -2.13052900e-02  2.26842736e-04  5.35707827e-05\n",
      " -6.92888209e-04  3.84678680e+02  6.73422241e+01 -7.44161415e+00\n",
      "  3.52972565e+01  2.48653755e+01  1.00527420e+01  1.69245567e+01\n",
      "  1.17348299e+01  2.14188719e+00  3.20608592e+00 -3.73420286e+00\n",
      "  4.27415133e+00  8.14015388e+00]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"[INFO] Combined data shape:\", combined_data.shape)\n",
    "print(\"[INFO] Combined label shape:\", combined_labels.shape)\n",
    "print(\"[INFO] Example entry (first window, first time step):\", combined_data[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d271430",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabelEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m y = binary_labels[valid_indices]\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Encode labels\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m label_encoder = \u001b[43mLabelEncoder\u001b[49m()\n\u001b[32m     14\u001b[39m y_encoded = label_encoder.fit_transform(y)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Convert to tensors\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'LabelEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "# Map labels from original multi-class to binary\n",
    "def map_labels(original_labels):\n",
    "    label_map = {2: 0, 3: 1}  # 0: tightening, 1: untightening\n",
    "    return np.array([label_map[label] if label in label_map else -1 for label in original_labels])\n",
    "\n",
    "# Filter and preprocess the data\n",
    "binary_labels = map_labels(combined_labels)\n",
    "valid_indices = binary_labels != -1\n",
    "X = combined_data[valid_indices, :, 1:]  # exclude timestamps\n",
    "y = binary_labels[valid_indices]\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.FloatTensor(X)\n",
    "y_tensor = torch.LongTensor(y_encoded)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tensor, y_tensor, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Print label distribution\n",
    "unique_train, counts_train = torch.unique(y_train, return_counts=True)\n",
    "unique_test, counts_test = torch.unique(y_test, return_counts=True)\n",
    "\n",
    "print(\"Training label distribution:\")\n",
    "for label, count in zip(unique_train.tolist(), counts_train.tolist()):\n",
    "    print(f\"  Label {label_encoder.inverse_transform([label])[0]}: {count} samples\")\n",
    "\n",
    "print(\"Testing label distribution:\")\n",
    "for label, count in zip(unique_test.tolist(), counts_test.tolist()):\n",
    "    print(f\"  Label {label_encoder.inverse_transform([label])[0]}: {count} samples\")\n",
    "\n",
    "# Normalize input features\n",
    "scalers = {}\n",
    "for i in range(X_train.shape[2]):\n",
    "    scalers[i] = StandardScaler()\n",
    "    X_train[:, :, i] = torch.FloatTensor(scalers[i].fit_transform(X_train[:, :, i]))\n",
    "    X_test[:, :, i] = torch.FloatTensor(scalers[i].transform(X_test[:, :, i]))\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Enhanced LSTM model with more hidden layers\n",
    "class EnhancedToolLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, num_classes):\n",
    "        super(EnhancedToolLSTM, self).__init__()\n",
    "        # Three LSTM layers\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size1, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.lstm2 = nn.LSTM(hidden_size1, hidden_size2, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.lstm3 = nn.LSTM(hidden_size2, hidden_size3, batch_first=True)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "\n",
    "        # Expanded fully connected layers\n",
    "        self.fc1 = nn.Linear(hidden_size3, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, 16)\n",
    "        self.output = nn.Linear(16, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm1(x)\n",
    "        out = self.dropout1(out)\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = self.dropout2(out)\n",
    "        out, _ = self.lstm3(out)\n",
    "        out = self.dropout3(out)\n",
    "        out = out[:, -1, :]  # Last time step\n",
    "\n",
    "        out = self.leaky_relu(self.bn1(self.fc1(out)))\n",
    "        out = self.leaky_relu(self.bn2(self.fc2(out)))\n",
    "        out = self.leaky_relu(self.bn3(self.fc3(out)))\n",
    "        out = self.relu(self.fc4(out))\n",
    "        out = self.relu(self.fc5(out))\n",
    "        out = self.output(out)\n",
    "        return out\n",
    "\n",
    "# Dynamic Focal Loss with adjustable class weights\n",
    "class DynamicFocalLoss(nn.Module):\n",
    "    def __init__(self, initial_weights=None, gamma=2.0, adjustment_rate=0.1, max_adjustment=0.5):\n",
    "        super(DynamicFocalLoss, self).__init__()\n",
    "        self.initial_weights = initial_weights\n",
    "        self.weights = initial_weights.clone() if initial_weights is not None else None\n",
    "        self.gamma = gamma\n",
    "        self.adjustment_rate = adjustment_rate\n",
    "        self.max_adjustment = max_adjustment\n",
    "        self.class_performance = None\n",
    "\n",
    "    def update_weights(self, class_performance):\n",
    "        \"\"\"Adjust weights based on class performance (accuracy per class)\"\"\"\n",
    "        if self.weights is None:\n",
    "            return\n",
    "            \n",
    "        # Calculate adjustment factor (boost weights for poorly performing classes)\n",
    "        adjustment_factors = 1.0 - class_performance\n",
    "        adjustment_factors = torch.clamp(adjustment_factors * self.adjustment_rate, \n",
    "                                      -self.max_adjustment, self.max_adjustment)\n",
    "        \n",
    "        # Apply adjustment\n",
    "        new_weights = self.weights * (1 + adjustment_factors)\n",
    "        new_weights = new_weights / new_weights.sum()  # Renormalize\n",
    "        \n",
    "        # Store for next epoch\n",
    "        self.weights = new_weights\n",
    "        self.class_performance = class_performance\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        logpt = nn.functional.log_softmax(inputs, dim=1)\n",
    "        pt = torch.exp(logpt)\n",
    "        logpt = logpt.gather(1, targets.view(-1, 1))\n",
    "        pt = pt.gather(1, targets.view(-1, 1))\n",
    "\n",
    "        if self.weights is not None:\n",
    "            weights_t = self.weights.gather(0, targets)\n",
    "            logpt = logpt * weights_t.view(-1, 1)\n",
    "\n",
    "        loss = -1 * (1 - pt) ** self.gamma * logpt\n",
    "        return loss.mean()\n",
    "\n",
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EnhancedToolLSTM(input_size=X.shape[2], \n",
    "                        hidden_size1=128, \n",
    "                        hidden_size2=64, \n",
    "                        hidden_size3=32, \n",
    "                        num_classes=2).to(device)\n",
    "\n",
    "# Initialize class weights (inverse of class frequencies)\n",
    "initial_weights = 1. / counts_train.float()\n",
    "initial_weights = initial_weights / initial_weights.sum()\n",
    "initial_weights = initial_weights.to(device)\n",
    "\n",
    "# Dynamic loss function\n",
    "criterion = DynamicFocalLoss(initial_weights=initial_weights, \n",
    "                           gamma=2.0, \n",
    "                           adjustment_rate=0.1,\n",
    "                           max_adjustment=0.3)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "\n",
    "# Initialize containers for tracking metrics\n",
    "train_losses, test_losses = [], []\n",
    "train_accuracies, test_accuracies = [], []\n",
    "class_performance_history = []  # To track per-class accuracy\n",
    "\n",
    "# Training loop with test evaluation each epoch\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    correct, total = 0, 0\n",
    "    running_loss = 0.0\n",
    "    class_correct = torch.zeros_like(initial_weights)\n",
    "    class_total = torch.zeros_like(initial_weights)\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Track per-class accuracy\n",
    "        for l in torch.unique(labels):\n",
    "            mask = labels == l\n",
    "            class_correct[l] += (predicted[mask] == labels[mask]).sum().item()\n",
    "            class_total[l] += mask.sum().item()\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accuracies.append(correct / total)\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    class_performance = class_correct / class_total.clamp(min=1)  # Avoid division by zero\n",
    "    class_performance_history.append(class_performance.cpu().numpy())\n",
    "    \n",
    "    # Update class weights based on performance\n",
    "    criterion.update_weights(class_performance)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct, test_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    test_losses.append(test_loss / len(test_loader))\n",
    "    test_accuracies.append(test_correct / test_total)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(test_losses[-1])\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"  Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}\")\n",
    "    print(f\"  Train Acc: {train_accuracies[-1]:.4f}, Test Acc: {test_accuracies[-1]:.4f}\")\n",
    "    print(f\"  Class Performance: {dict(zip([label_encoder.inverse_transform([i])[0] for i in range(len(class_performance))], [f'{acc:.4f}' for acc in class_performance]))}\")\n",
    "    print(f\"  Current Weights: {dict(zip([label_encoder.inverse_transform([i])[0] for i in range(len(criterion.weights))], [f'{w:.4f}' for w in criterion.weights]))}\")\n",
    "    print(f\"  Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "# Final evaluation\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(f\"\\nFinal Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Final F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "TT = cm[0, 0]\n",
    "TF = cm[0, 1]\n",
    "FT = cm[1, 0]\n",
    "FF = cm[1, 1]\n",
    "print(f\"TT (True tightening): {TT}\")\n",
    "print(f\"TF (Tightening predicted as untightening): {TF}\")\n",
    "print(f\"FT (Untightening predicted as tightening): {FT}\")\n",
    "print(f\"FF (True untightening): {FF}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['tightening', 'untightening']))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['tightening', 'untightening'],\n",
    "            yticklabels=['tightening', 'untightening'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Class Performance\n",
    "plt.subplot(2, 2, 4)\n",
    "class_perf_array = np.array(class_performance_history)\n",
    "for i in range(class_perf_array.shape[1]):\n",
    "    plt.plot(class_perf_array[:, i], label=f'{label_encoder.inverse_transform([i])[0]} accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Class Accuracy')\n",
    "plt.title('Class-wise Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500fc8df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tool-tracking_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
